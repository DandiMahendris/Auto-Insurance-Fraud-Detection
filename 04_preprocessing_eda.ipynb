{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Import Libraries](#toc1_)    \n",
    "    - [Import Configuration File](#toc1_1_1_)    \n",
    "    - [Load Dataset](#toc1_1_2_)    \n",
    "- [<b>Removing Outlier</b>](#toc2_)    \n",
    "- [<b>Handling Missing Value</b>](#toc3_)    \n",
    "  - [Splitting data into X_train & y_train](#toc3_1_)    \n",
    "  - [Splitting data into Numeric & Categoric Features](#toc3_2_)    \n",
    "  - [Handling Numeric Features](#toc3_3_)    \n",
    "    - [Handling missing value on numeric features](#toc3_3_1_)    \n",
    "  - [Handling Categorical Data](#toc3_4_)    \n",
    "    - [Handling missing value for Categoric Features](#toc3_4_1_)    \n",
    "- [<b>Label Encoding</b>](#toc4_)    \n",
    "  - [One Hot Encoder (OHE)](#toc4_1_)    \n",
    "  - [Ordinal Encoding](#toc4_2_)    \n",
    "  - [Encoding Categoric Features](#toc4_3_)    \n",
    "  - [Concatenate Imputed Numeric & ENcoded Categoric Features](#toc4_4_)    \n",
    "- [<b>Scaling Data</b>](#toc5_)    \n",
    "- [<b>Handling Label Data</b>](#toc6_)    \n",
    "  - [Label Categories](#toc6_1_)    \n",
    "  - [Balancing Train Data](#toc6_2_)    \n",
    "- [<b>Handling Valid & Test set</b>](#toc7_)    \n",
    "  - [Function](#toc7_1_)    \n",
    "  - [Handling Non-Balancing Valid & Test set](#toc7_2_)    \n",
    "  - [Handling Smote Data Set](#toc7_3_)    \n",
    "  - [Handling Over Data Set](#toc7_4_)    \n",
    "- [<b> Dump Train, Valid & Test Set </b>](#toc8_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Import Libraries](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import src.util as util\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, OrdinalEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_1_'></a>[Import Configuration File](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_data = util.load_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_2_'></a>[Load Dataset](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(config_data: dict, config: str) -> pd.DataFrame:\n",
    "    # Load set of data\n",
    "    x_train = util.pickle_load(config_data[\"train_set_eda\"][0])\n",
    "    y_train = util.pickle_load(config_data[\"train_set_eda\"][1])\n",
    "\n",
    "    x_valid = util.pickle_load(config_data[\"valid_set_eda\"][0])\n",
    "    y_valid = util.pickle_load(config_data[\"valid_set_eda\"][1])\n",
    "\n",
    "    x_test = util.pickle_load(config_data[\"test_set_eda\"][0])\n",
    "    y_test = util.pickle_load(config_data[\"test_set_eda\"][1])\n",
    "\n",
    "    # concatenate x and y each set\n",
    "    train_set = pd.concat([x_train[config], y_train[config]], axis = 1)\n",
    "    valid_set = pd.concat([x_valid[config], y_valid[config]], axis = 1)\n",
    "    test_set = pd.concat([x_test[config], y_test[config]], axis = 1)\n",
    "\n",
    "    # return 3 set of data\n",
    "    return train_set, valid_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, valid_set, test_set = load_dataset(config_data, 'nonbalance')\n",
    "train_set_smote, valid_set_smote, test_set_smote = load_dataset(config_data, 'smote')\n",
    "train_set_over, valid_set_over, test_set_over = load_dataset(config_data, 'oversampling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse_map = {0: 'N', 1: 'Y'}\n",
    "\n",
    "# train_set.fraud_reported = train_set.fraud_reported.map(reverse_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[<b>Removing Outlier</b>](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outlier(set_data):\n",
    "    set_data = set_data.copy()\n",
    "    list_of_set_data = list()\n",
    "\n",
    "    for col in set_data[config_data['numeric_eda']]:\n",
    "        q1 = set_data[col].quantile(0.25)\n",
    "        q3 = set_data[col].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "\n",
    "        set_data_cleaned = set_data[~((set_data[col] < (q1 - 1.5*iqr)) |\n",
    "                                    (set_data[col] > (q3 + 1.5*iqr)))].copy()\n",
    "        list_of_set_data.append(set_data_cleaned.copy())\n",
    "\n",
    "    set_data_cleaned = pd.concat(list_of_set_data)\n",
    "    count_duplicated_index = set_data_cleaned.index.value_counts()\n",
    "    used_index_data = count_duplicated_index[count_duplicated_index == len(config_data['int32_col'])].index\n",
    "    set_data_cleaned = set_data_cleaned.loc[used_index_data].drop_duplicates()\n",
    "\n",
    "    return set_data_cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_out = remove_outlier(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[<b>Handling Missing Value</b>](#toc0_)\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_1_'></a>[Splitting data into X_train & y_train](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_xy(set_data):\n",
    "    x_data = set_data.drop(columns = config_data['label'], axis = 1)\n",
    "    y_data = set_data[config_data['label']]\n",
    "\n",
    "    return x_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = split_xy(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_2_'></a>[Splitting data into Numeric & Categoric Features](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_NumCat(set_data):\n",
    "\n",
    "    num = set_data[config_data['numeric_eda']]\n",
    "    cat = set_data[config_data['categoric_eda']]\n",
    "\n",
    "    return  num, cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_num, x_train_cat = split_NumCat(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_3_'></a>[Handling Numeric Features](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "injury_claim      False\n",
       "property_claim    False\n",
       "vehicle_claim     False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_num.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_3_1_'></a>[Handling missing value on numeric features](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform sanity check for any missing value for future data\n",
    "\n",
    "def imputer_Num(data, imputer = None):\n",
    "\n",
    "    if imputer == None:\n",
    "        # Create imputer based on median value\n",
    "        imputer = SimpleImputer(missing_values = np.nan,\n",
    "                                strategy = \"median\")\n",
    "        imputer.fit(data)\n",
    "\n",
    "    # Transform data dengan imputer\n",
    "\n",
    "    data_imputed = pd.DataFrame(imputer.transform(data),\n",
    "                                index = data.index,\n",
    "                                columns = data.columns)\n",
    "    \n",
    "    # Convert data_imputed to int32\n",
    "    data_imputed = data_imputed.astype('int32')\n",
    "    \n",
    "    return data_imputed, imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_num_imputed, imputer_num = imputer_Num(data = x_train_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_4_'></a>[Handling Categorical Data](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_4_1_'></a>[Handling missing value for Categoric Features](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputer_Cat(data, imputer = None):\n",
    "        \n",
    "    if imputer == None:\n",
    "        # Create Imputer\n",
    "        imputer = SimpleImputer(missing_values = np.nan,\n",
    "                                strategy = 'constant',\n",
    "                                fill_value = 'UNKNOWN')\n",
    "        imputer.fit(data)\n",
    "\n",
    "    # Transform data with imputer\n",
    "    data_imputed = imputer.transform(data)\n",
    "    data_imputed = pd.DataFrame(data_imputed,\n",
    "                                index = data.index,\n",
    "                                columns = data.columns)\n",
    "\n",
    "    return data_imputed, imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_cat_imputed, imputer_cat = imputer_Cat(data = x_train_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc4_'></a>[<b>Label Encoding</b>](#toc0_)\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc4_1_'></a>[One Hot Encoder (OHE)](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>insured_hobbies</th>\n",
       "      <th>incident_type</th>\n",
       "      <th>collision_type</th>\n",
       "      <th>incident_severity</th>\n",
       "      <th>authorities_contacted</th>\n",
       "      <th>incident_state</th>\n",
       "      <th>property_damage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>exercise</td>\n",
       "      <td>Parked Car</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>Minor Damage</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>VA</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>camping</td>\n",
       "      <td>Multi-vehicle Collision</td>\n",
       "      <td>Side Collision</td>\n",
       "      <td>Total Loss</td>\n",
       "      <td>Ambulance</td>\n",
       "      <td>VA</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>reading</td>\n",
       "      <td>Single Vehicle Collision</td>\n",
       "      <td>Rear Collision</td>\n",
       "      <td>Major Damage</td>\n",
       "      <td>Ambulance</td>\n",
       "      <td>NY</td>\n",
       "      <td>UNKNOWN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>basketball</td>\n",
       "      <td>Multi-vehicle Collision</td>\n",
       "      <td>Side Collision</td>\n",
       "      <td>Major Damage</td>\n",
       "      <td>Police</td>\n",
       "      <td>WV</td>\n",
       "      <td>UNKNOWN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>basketball</td>\n",
       "      <td>Single Vehicle Collision</td>\n",
       "      <td>Rear Collision</td>\n",
       "      <td>Total Loss</td>\n",
       "      <td>Other</td>\n",
       "      <td>WV</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    insured_hobbies             incident_type  collision_type  \\\n",
       "887        exercise                Parked Car         UNKNOWN   \n",
       "317         camping   Multi-vehicle Collision  Side Collision   \n",
       "796         reading  Single Vehicle Collision  Rear Collision   \n",
       "425      basketball   Multi-vehicle Collision  Side Collision   \n",
       "991      basketball  Single Vehicle Collision  Rear Collision   \n",
       "\n",
       "    incident_severity authorities_contacted incident_state property_damage  \n",
       "887      Minor Damage               UNKNOWN             VA              NO  \n",
       "317        Total Loss             Ambulance             VA             YES  \n",
       "796      Major Damage             Ambulance             NY         UNKNOWN  \n",
       "425      Major Damage                Police             WV         UNKNOWN  \n",
       "991        Total Loss                 Other             WV              NO  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_cat_imputed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>columns</th>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">authorities_contacted</th>\n",
       "      <th>Ambulance</th>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Police</th>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNKNOWN</th>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fire</th>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">collision_type</th>\n",
       "      <th>Side Collision</th>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNKNOWN</th>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rear Collision</th>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Front Collision</th>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">incident_severity</th>\n",
       "      <th>Trivial Damage</th>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minor Damage</th>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Loss</th>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Major Damage</th>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">incident_state</th>\n",
       "      <th>WV</th>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OH</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NY</th>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NC</th>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PA</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SC</th>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VA</th>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">incident_type</th>\n",
       "      <th>Parked Car</th>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multi-vehicle Collision</th>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vehicle Theft</th>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Single Vehicle Collision</th>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"20\" valign=\"top\">insured_hobbies</th>\n",
       "      <th>cross-fit</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sleeping</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>board-games</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polo</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video-games</th>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chess</th>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yachting</th>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>camping</th>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dancing</th>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hiking</th>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exercise</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skydiving</th>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bungie-jumping</th>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>golf</th>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movies</th>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kayaking</th>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paintball</th>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reading</th>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>basketball</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base-jumping</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">property_damage</th>\n",
       "      <th>YES</th>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNKNOWN</th>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NO</th>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  0\n",
       "columns               index                        \n",
       "authorities_contacted Ambulance                 154\n",
       "                      Police                    235\n",
       "                      UNKNOWN                    82\n",
       "                      Other                     156\n",
       "                      Fire                      173\n",
       "collision_type        Side Collision            212\n",
       "                      UNKNOWN                   152\n",
       "                      Rear Collision            232\n",
       "                      Front Collision           204\n",
       "incident_severity     Trivial Damage             75\n",
       "                      Minor Damage              281\n",
       "                      Total Loss                225\n",
       "                      Major Damage              219\n",
       "incident_state        WV                        174\n",
       "                      OH                         18\n",
       "                      NY                        205\n",
       "                      NC                         94\n",
       "                      PA                         28\n",
       "                      SC                        194\n",
       "                      VA                         87\n",
       "incident_type         Parked Car                 77\n",
       "                      Multi-vehicle Collision   334\n",
       "                      Vehicle Theft              75\n",
       "                      Single Vehicle Collision  314\n",
       "insured_hobbies       cross-fit                  28\n",
       "                      sleeping                   32\n",
       "                      board-games                35\n",
       "                      polo                       37\n",
       "                      video-games                38\n",
       "                      chess                      38\n",
       "                      yachting                   39\n",
       "                      camping                    39\n",
       "                      dancing                    39\n",
       "                      hiking                     39\n",
       "                      exercise                   42\n",
       "                      skydiving                  43\n",
       "                      bungie-jumping             44\n",
       "                      golf                       44\n",
       "                      movies                     46\n",
       "                      kayaking                   46\n",
       "                      paintball                  52\n",
       "                      reading                    54\n",
       "                      basketball                 25\n",
       "                      base-jumping               40\n",
       "property_damage       YES                       232\n",
       "                      UNKNOWN                   286\n",
       "                      NO                        282"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(x_train_cat_imputed\n",
    "            .melt(var_name='columns', value_name='index')\n",
    "            .value_counts()).sort_values(by=['columns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal = ['authorities_contacted', 'incident_state', 'insured_hobbies',  'property_damage']\n",
    "ordinal = ['collision_type', 'incident_type', 'incident_severity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OHE_cat(data, encoder_col = None, encoder = None) -> pd.DataFrame:\n",
    "\n",
    "    data_ohe = data[nominal]\n",
    "\n",
    "    if encoder == None:\n",
    "        # Create Object\n",
    "        encoder = OneHotEncoder(handle_unknown = 'ignore',\n",
    "                                drop = 'if_binary')\n",
    "        encoder.fit(data_ohe)\n",
    "        encoder_col = encoder.get_feature_names_out(data_ohe.columns)\n",
    "    \n",
    "    \n",
    "    # Transform the data\n",
    "    data_encoded = encoder.transform(data_ohe).toarray()\n",
    "    data_encoded = pd.DataFrame(data_encoded,\n",
    "                                index = data_ohe.index,\n",
    "                                columns = encoder_col)\n",
    "    \n",
    "    # Save the object\n",
    "    util.pickle_dump(encoder, config_data[\"ohe_path\"])\n",
    "\n",
    "    return data_encoded, encoder_col, encoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc4_2_'></a>[Ordinal Encoding](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OE_cat(data, encoder = None) -> pd.DataFrame:\n",
    "\n",
    "    data_le = data[ordinal]\n",
    "\n",
    "    collision_type = ['UNKNOWN', 'Side Collision', 'Rear Collision', 'Front Collision']\n",
    "    incident_severity = ['Trivial Damage','Minor Damage','Major Damage','Total Loss']\n",
    "    incident_type = ['Parked Car','Single Vehicle Collision','Multi-vehicle Collision','Vehicle Theft']\n",
    "\n",
    "    if encoder == None:\n",
    "        # Create object\n",
    "        encoder = OrdinalEncoder(categories=[collision_type, incident_type,incident_severity])\n",
    "        encoder.fit(data_le)\n",
    "\n",
    "    ## Transform the data\n",
    "    data_encoded = encoder.transform(data_le)\n",
    "    data_encoded = pd.DataFrame(data_encoded,\n",
    "                                index = data_le.index,\n",
    "                                columns = data_le.columns)\n",
    "    \n",
    "    # save the object\n",
    "    util.pickle_dump(encoder, config_data[\"le_path\"])\n",
    "\n",
    "    return data_encoded, encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc4_3_'></a>[Encoding Categoric Features](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_cat_ohe, encoder_ohe_col, encoder_ohe = OHE_cat(data = x_train_cat_imputed)\n",
    "x_train_cat_oe, encoder_oe = OE_cat(data = x_train_cat_imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc4_4_'></a>[Concatenate Imputed Numeric & ENcoded Categoric Features](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_concat = pd.concat([x_train_num_imputed, x_train_cat_ohe, x_train_cat_oe], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>injury_claim</th>\n",
       "      <th>property_claim</th>\n",
       "      <th>vehicle_claim</th>\n",
       "      <th>authorities_contacted_Ambulance</th>\n",
       "      <th>authorities_contacted_Fire</th>\n",
       "      <th>authorities_contacted_Other</th>\n",
       "      <th>authorities_contacted_Police</th>\n",
       "      <th>authorities_contacted_UNKNOWN</th>\n",
       "      <th>incident_state_NC</th>\n",
       "      <th>incident_state_NY</th>\n",
       "      <th>...</th>\n",
       "      <th>insured_hobbies_skydiving</th>\n",
       "      <th>insured_hobbies_sleeping</th>\n",
       "      <th>insured_hobbies_video-games</th>\n",
       "      <th>insured_hobbies_yachting</th>\n",
       "      <th>property_damage_NO</th>\n",
       "      <th>property_damage_UNKNOWN</th>\n",
       "      <th>property_damage_YES</th>\n",
       "      <th>collision_type</th>\n",
       "      <th>incident_type</th>\n",
       "      <th>incident_severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>640</td>\n",
       "      <td>640</td>\n",
       "      <td>5120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>5360</td>\n",
       "      <td>10720</td>\n",
       "      <td>48240</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>16860</td>\n",
       "      <td>8430</td>\n",
       "      <td>67440</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>6080</td>\n",
       "      <td>12160</td>\n",
       "      <td>48640</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>0</td>\n",
       "      <td>5220</td>\n",
       "      <td>41760</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     injury_claim  property_claim  vehicle_claim  \\\n",
       "887           640             640           5120   \n",
       "317          5360           10720          48240   \n",
       "796         16860            8430          67440   \n",
       "425          6080           12160          48640   \n",
       "991             0            5220          41760   \n",
       "\n",
       "     authorities_contacted_Ambulance  authorities_contacted_Fire  \\\n",
       "887                              0.0                         0.0   \n",
       "317                              1.0                         0.0   \n",
       "796                              1.0                         0.0   \n",
       "425                              0.0                         0.0   \n",
       "991                              0.0                         0.0   \n",
       "\n",
       "     authorities_contacted_Other  authorities_contacted_Police  \\\n",
       "887                          0.0                           0.0   \n",
       "317                          0.0                           0.0   \n",
       "796                          0.0                           0.0   \n",
       "425                          0.0                           1.0   \n",
       "991                          1.0                           0.0   \n",
       "\n",
       "     authorities_contacted_UNKNOWN  incident_state_NC  incident_state_NY  ...  \\\n",
       "887                            1.0                0.0                0.0  ...   \n",
       "317                            0.0                0.0                0.0  ...   \n",
       "796                            0.0                0.0                1.0  ...   \n",
       "425                            0.0                0.0                0.0  ...   \n",
       "991                            0.0                0.0                0.0  ...   \n",
       "\n",
       "     insured_hobbies_skydiving  insured_hobbies_sleeping  \\\n",
       "887                        0.0                       0.0   \n",
       "317                        0.0                       0.0   \n",
       "796                        0.0                       0.0   \n",
       "425                        0.0                       0.0   \n",
       "991                        0.0                       0.0   \n",
       "\n",
       "     insured_hobbies_video-games  insured_hobbies_yachting  \\\n",
       "887                          0.0                       0.0   \n",
       "317                          0.0                       0.0   \n",
       "796                          0.0                       0.0   \n",
       "425                          0.0                       0.0   \n",
       "991                          0.0                       0.0   \n",
       "\n",
       "     property_damage_NO  property_damage_UNKNOWN  property_damage_YES  \\\n",
       "887                 1.0                      0.0                  0.0   \n",
       "317                 0.0                      0.0                  1.0   \n",
       "796                 0.0                      1.0                  0.0   \n",
       "425                 0.0                      1.0                  0.0   \n",
       "991                 1.0                      0.0                  0.0   \n",
       "\n",
       "     collision_type  incident_type  incident_severity  \n",
       "887             0.0            0.0                1.0  \n",
       "317             1.0            2.0                3.0  \n",
       "796             2.0            1.0                2.0  \n",
       "425             1.0            2.0                2.0  \n",
       "991             2.0            1.0                3.0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Sanity Check\n",
    "x_train_concat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc5_'></a>[<b>Scaling Data</b>](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling_Data(data, scaler=None):\n",
    "\n",
    "    if scaler == None:\n",
    "\n",
    "        # Create Fit Scaler\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(data)\n",
    "\n",
    "    # Transform data\n",
    "    data_scaled = scaler.transform(data)\n",
    "\n",
    "    data_scaled = pd.DataFrame(data_scaled,\n",
    "                                index = data.index,\n",
    "                                columns = data.columns)\n",
    "    \n",
    "    return data_scaled, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled, scaler = scaling_Data(data = x_train_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 41)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>injury_claim</th>\n",
       "      <th>property_claim</th>\n",
       "      <th>vehicle_claim</th>\n",
       "      <th>authorities_contacted_Ambulance</th>\n",
       "      <th>authorities_contacted_Fire</th>\n",
       "      <th>authorities_contacted_Other</th>\n",
       "      <th>authorities_contacted_Police</th>\n",
       "      <th>authorities_contacted_UNKNOWN</th>\n",
       "      <th>incident_state_NC</th>\n",
       "      <th>incident_state_NY</th>\n",
       "      <th>...</th>\n",
       "      <th>insured_hobbies_skydiving</th>\n",
       "      <th>insured_hobbies_sleeping</th>\n",
       "      <th>insured_hobbies_video-games</th>\n",
       "      <th>insured_hobbies_yachting</th>\n",
       "      <th>property_damage_NO</th>\n",
       "      <th>property_damage_UNKNOWN</th>\n",
       "      <th>property_damage_YES</th>\n",
       "      <th>collision_type</th>\n",
       "      <th>incident_type</th>\n",
       "      <th>incident_severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>-1.361866</td>\n",
       "      <td>-1.367596</td>\n",
       "      <td>-1.676726</td>\n",
       "      <td>-0.488252</td>\n",
       "      <td>-0.525278</td>\n",
       "      <td>-0.492175</td>\n",
       "      <td>-0.644926</td>\n",
       "      <td>2.959070</td>\n",
       "      <td>-0.36489</td>\n",
       "      <td>-0.586973</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.238334</td>\n",
       "      <td>-0.204124</td>\n",
       "      <td>-0.223313</td>\n",
       "      <td>-0.226381</td>\n",
       "      <td>1.355315</td>\n",
       "      <td>-0.745936</td>\n",
       "      <td>-0.639101</td>\n",
       "      <td>-1.515970</td>\n",
       "      <td>-1.900962</td>\n",
       "      <td>-0.765344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>-0.407244</td>\n",
       "      <td>0.694777</td>\n",
       "      <td>0.557802</td>\n",
       "      <td>2.048122</td>\n",
       "      <td>-0.525278</td>\n",
       "      <td>-0.492175</td>\n",
       "      <td>-0.644926</td>\n",
       "      <td>-0.337944</td>\n",
       "      <td>-0.36489</td>\n",
       "      <td>-0.586973</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.238334</td>\n",
       "      <td>-0.204124</td>\n",
       "      <td>-0.223313</td>\n",
       "      <td>-0.226381</td>\n",
       "      <td>-0.737836</td>\n",
       "      <td>-0.745936</td>\n",
       "      <td>1.564697</td>\n",
       "      <td>-0.574374</td>\n",
       "      <td>0.618954</td>\n",
       "      <td>1.296189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>1.918636</td>\n",
       "      <td>0.226242</td>\n",
       "      <td>1.552769</td>\n",
       "      <td>2.048122</td>\n",
       "      <td>-0.525278</td>\n",
       "      <td>-0.492175</td>\n",
       "      <td>-0.644926</td>\n",
       "      <td>-0.337944</td>\n",
       "      <td>-0.36489</td>\n",
       "      <td>1.703655</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.238334</td>\n",
       "      <td>-0.204124</td>\n",
       "      <td>-0.223313</td>\n",
       "      <td>-0.226381</td>\n",
       "      <td>-0.737836</td>\n",
       "      <td>1.340598</td>\n",
       "      <td>-0.639101</td>\n",
       "      <td>0.367223</td>\n",
       "      <td>-0.641004</td>\n",
       "      <td>0.265422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>-0.261624</td>\n",
       "      <td>0.989402</td>\n",
       "      <td>0.578531</td>\n",
       "      <td>-0.488252</td>\n",
       "      <td>-0.525278</td>\n",
       "      <td>-0.492175</td>\n",
       "      <td>1.550566</td>\n",
       "      <td>-0.337944</td>\n",
       "      <td>-0.36489</td>\n",
       "      <td>-0.586973</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.238334</td>\n",
       "      <td>-0.204124</td>\n",
       "      <td>-0.223313</td>\n",
       "      <td>-0.226381</td>\n",
       "      <td>-0.737836</td>\n",
       "      <td>1.340598</td>\n",
       "      <td>-0.639101</td>\n",
       "      <td>-0.574374</td>\n",
       "      <td>0.618954</td>\n",
       "      <td>0.265422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>-1.491306</td>\n",
       "      <td>-0.430526</td>\n",
       "      <td>0.222001</td>\n",
       "      <td>-0.488252</td>\n",
       "      <td>-0.525278</td>\n",
       "      <td>2.031798</td>\n",
       "      <td>-0.644926</td>\n",
       "      <td>-0.337944</td>\n",
       "      <td>-0.36489</td>\n",
       "      <td>-0.586973</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.238334</td>\n",
       "      <td>-0.204124</td>\n",
       "      <td>-0.223313</td>\n",
       "      <td>-0.226381</td>\n",
       "      <td>1.355315</td>\n",
       "      <td>-0.745936</td>\n",
       "      <td>-0.639101</td>\n",
       "      <td>0.367223</td>\n",
       "      <td>-0.641004</td>\n",
       "      <td>1.296189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     injury_claim  property_claim  vehicle_claim  \\\n",
       "887     -1.361866       -1.367596      -1.676726   \n",
       "317     -0.407244        0.694777       0.557802   \n",
       "796      1.918636        0.226242       1.552769   \n",
       "425     -0.261624        0.989402       0.578531   \n",
       "991     -1.491306       -0.430526       0.222001   \n",
       "\n",
       "     authorities_contacted_Ambulance  authorities_contacted_Fire  \\\n",
       "887                        -0.488252                   -0.525278   \n",
       "317                         2.048122                   -0.525278   \n",
       "796                         2.048122                   -0.525278   \n",
       "425                        -0.488252                   -0.525278   \n",
       "991                        -0.488252                   -0.525278   \n",
       "\n",
       "     authorities_contacted_Other  authorities_contacted_Police  \\\n",
       "887                    -0.492175                     -0.644926   \n",
       "317                    -0.492175                     -0.644926   \n",
       "796                    -0.492175                     -0.644926   \n",
       "425                    -0.492175                      1.550566   \n",
       "991                     2.031798                     -0.644926   \n",
       "\n",
       "     authorities_contacted_UNKNOWN  incident_state_NC  incident_state_NY  ...  \\\n",
       "887                       2.959070           -0.36489          -0.586973  ...   \n",
       "317                      -0.337944           -0.36489          -0.586973  ...   \n",
       "796                      -0.337944           -0.36489           1.703655  ...   \n",
       "425                      -0.337944           -0.36489          -0.586973  ...   \n",
       "991                      -0.337944           -0.36489          -0.586973  ...   \n",
       "\n",
       "     insured_hobbies_skydiving  insured_hobbies_sleeping  \\\n",
       "887                  -0.238334                 -0.204124   \n",
       "317                  -0.238334                 -0.204124   \n",
       "796                  -0.238334                 -0.204124   \n",
       "425                  -0.238334                 -0.204124   \n",
       "991                  -0.238334                 -0.204124   \n",
       "\n",
       "     insured_hobbies_video-games  insured_hobbies_yachting  \\\n",
       "887                    -0.223313                 -0.226381   \n",
       "317                    -0.223313                 -0.226381   \n",
       "796                    -0.223313                 -0.226381   \n",
       "425                    -0.223313                 -0.226381   \n",
       "991                    -0.223313                 -0.226381   \n",
       "\n",
       "     property_damage_NO  property_damage_UNKNOWN  property_damage_YES  \\\n",
       "887            1.355315                -0.745936            -0.639101   \n",
       "317           -0.737836                -0.745936             1.564697   \n",
       "796           -0.737836                 1.340598            -0.639101   \n",
       "425           -0.737836                 1.340598            -0.639101   \n",
       "991            1.355315                -0.745936            -0.639101   \n",
       "\n",
       "     collision_type  incident_type  incident_severity  \n",
       "887       -1.515970      -1.900962          -0.765344  \n",
       "317       -0.574374       0.618954           1.296189  \n",
       "796        0.367223      -0.641004           0.265422  \n",
       "425       -0.574374       0.618954           0.265422  \n",
       "991        0.367223      -0.641004           1.296189  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc6_'></a>[<b>Handling Label Data</b>](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_clean = y_train.map(dict(Y=1, N=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Check X and y shape of data --- #\n",
    "\n",
    "x_train_scaled.shape[0] == y_train_clean.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_clean = pd.concat([x_train_scaled, y_train_clean], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc6_1_'></a>[Label Categories](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def le_fit(data_tobe_fitted: dict, le_path: str) -> LabelEncoder:\n",
    "    # Create le object\n",
    "    le_encoder = LabelEncoder()\n",
    "\n",
    "    # Fit le\n",
    "    le_encoder.fit(data_tobe_fitted)\n",
    "\n",
    "    # Save le object\n",
    "    util.pickle_dump(le_encoder, le_path)\n",
    "\n",
    "    # Return trained le\n",
    "    return le_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le_fit(config_data[\"label_categories\"], config_data[\"le_label_path\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc6_2_'></a>[Balancing Train Data](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balancing(data):\n",
    "    x_data = data.drop(columns = config_data['label'])\n",
    "    y_data = data[config_data['label']]\n",
    "\n",
    "    x_over, y_over = RandomOverSampler(random_state=42).fit_resample(x_data, y_data)\n",
    "    x_smote, y_smote = SMOTE(random_state=42).fit_resample(x_data, y_data)\n",
    "\n",
    "    train_set_smote = pd.concat([x_smote, y_smote], axis = 1)\n",
    "    train_set_over = pd.concat([x_over, y_over], axis = 1)\n",
    "\n",
    "    return x_smote, y_smote, x_over, y_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_smote, y_smote, x_over, y_over = balancing(train_set_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc7_'></a>[<b>Handling Valid & Test set</b>](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I create class function in order to simplify our work above in one function to handle valid and test data, also for .py file later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc7_1_'></a>[Function](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class preprocessing_data:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def split_xy(self, set_data):\n",
    "        self.x = set_data.drop(columns = config_data['label'], axis = 1)\n",
    "        self.y = set_data[config_data['label']].map(dict(Y=1, N=0))\n",
    "\n",
    "    def split_NumCat(self, set_data):\n",
    "\n",
    "        self.num = set_data[config_data['numeric_eda']]\n",
    "        self.cat = set_data[config_data['categoric_eda']]\n",
    "\n",
    "    def imputer_Num(self, data, imputer = None):\n",
    "\n",
    "        if imputer == None:\n",
    "            # Create imputer based on median value\n",
    "            imputer = SimpleImputer(missing_values = np.nan,\n",
    "                                    strategy = \"median\")\n",
    "            imputer.fit(data)\n",
    "\n",
    "        self.imputer_num = imputer\n",
    "        \n",
    "        # Transform data dengan imputer\n",
    "        imputed_data = pd.DataFrame(imputer.transform(data),\n",
    "                                    index = data.index,\n",
    "                                    columns = data.columns)\n",
    "        \n",
    "        # Convert data_imputed to int32\n",
    "        self.imputed_num = imputed_data.astype('int32')\n",
    "\n",
    "    def imputer_Cat(self, data, imputer = None) -> pd.DataFrame:\n",
    "        \n",
    "        if imputer == None:\n",
    "            # Create Imputer\n",
    "            imputer = SimpleImputer(missing_values = np.nan,\n",
    "                                    strategy = 'constant',\n",
    "                                    fill_value = 'UNKNOWN')\n",
    "            imputer.fit(data)\n",
    "\n",
    "        self.imputer_cat = imputer\n",
    "\n",
    "        # Transform data with imputer\n",
    "        data_imputed = imputer.transform(data)\n",
    "        data_imputed = pd.DataFrame(data_imputed,\n",
    "                                    index = data.index,\n",
    "                                    columns = data.columns)\n",
    "\n",
    "        self.imputed_cat = data_imputed\n",
    "\n",
    "    def OHE_cat(self, data, encoder = None) -> pd.DataFrame:\n",
    "\n",
    "        nominal = ['authorities_contacted', 'incident_state', 'insured_hobbies',  'property_damage']\n",
    "\n",
    "        data_ohe = data[nominal]\n",
    "\n",
    "        if encoder == None:\n",
    "            # Create Object\n",
    "            encoder = OneHotEncoder(handle_unknown = 'ignore',\n",
    "                                    drop = 'if_binary')\n",
    "            encoder.fit(data_ohe)\n",
    "            encoder_col = encoder.get_feature_names_out(data_ohe.columns)\n",
    "        \n",
    "        self.encoder_ohe = encoder\n",
    "\n",
    "        # Transform the data\n",
    "        encoder_col = encoder.get_feature_names_out(data_ohe.columns)\n",
    "\n",
    "        data_encoded = encoder.transform(data_ohe).toarray()\n",
    "        data_encoded = pd.DataFrame(data_encoded,\n",
    "                                    index = data_ohe.index,\n",
    "                                    columns = encoder_col)\n",
    "        \n",
    "        self.encoded_ohe = data_encoded\n",
    "\n",
    "    def OE_cat(self, data, encoder = None) -> pd.DataFrame:\n",
    "\n",
    "        ordinal = ['collision_type', 'incident_type', 'incident_severity']\n",
    "\n",
    "        data_le = data[ordinal]\n",
    "\n",
    "        collision_type = ['UNKNOWN', 'Side Collision', 'Rear Collision', 'Front Collision']\n",
    "        incident_severity = ['Trivial Damage','Minor Damage','Major Damage','Total Loss']\n",
    "        incident_type = ['Parked Car','Single Vehicle Collision','Multi-vehicle Collision','Vehicle Theft']\n",
    "\n",
    "        if encoder == None:\n",
    "            # Create object\n",
    "            encoder = OrdinalEncoder(categories=[collision_type, incident_type,incident_severity])\n",
    "            encoder.fit(data_le)\n",
    "\n",
    "        self.encoder_oe = encoder\n",
    "\n",
    "        ## Transform the data\n",
    "        data_encoded = encoder.transform(data_le)\n",
    "        data_encoded = pd.DataFrame(data_encoded,\n",
    "                                    index = data_le.index,\n",
    "                                    columns = data_le.columns)\n",
    "        \n",
    "        self.encoded_oe = data_encoded\n",
    "\n",
    "    def scaling_Data(self, data, scaler=None) -> pd.DataFrame:\n",
    "\n",
    "        if scaler == None:\n",
    "\n",
    "            # Create Fit Scaler\n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit(data)\n",
    "\n",
    "        self.scaler = scaler\n",
    "\n",
    "        # Transform data\n",
    "        data_scaled = scaler.transform(data)\n",
    "\n",
    "        data_scaled = pd.DataFrame(data_scaled,\n",
    "                                    index = data.index,\n",
    "                                    columns = data.columns)\n",
    "\n",
    "        self.scaled_data = data_scaled\n",
    "\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        data, \n",
    "        imputer_num=None, imputer_cat=None, \n",
    "        encoder_ohe=None, encoder_oe=None,\n",
    "        scaler=None,\n",
    "        y=True\n",
    "    ):\n",
    "\n",
    "        # Split features into numeric and categoric\n",
    "        if y == True:\n",
    "            self.split_xy(data)\n",
    "            self.split_NumCat(self.x)\n",
    "\n",
    "        else:\n",
    "            self.split_NumCat(x)\n",
    "\n",
    "        # Handling numeric features\n",
    "        self.imputer_Num(self.num, imputer=imputer_num)\n",
    "\n",
    "        # Handling categoric features\n",
    "        self.imputer_Cat(self.cat, imputer=imputer_cat)\n",
    "\n",
    "        # Label Encoding\n",
    "        self.OHE_cat(self.imputed_cat, encoder=encoder_ohe)\n",
    "\n",
    "        self.OE_cat(self.imputed_cat, encoder=encoder_oe)\n",
    "\n",
    "        # Concatenate imputed numeric and encoded categoric features\n",
    "        concatenated_data = pd.concat([self.imputed_num, self.encoded_oe, self.encoded_ohe], axis=1)\n",
    "\n",
    "        # Scaling data\n",
    "        self.scaling_Data(concatenated_data, scaler=scaler)\n",
    "\n",
    "        self.x_clean = self.scaled_data\n",
    "        \n",
    "        if y == True:\n",
    "            return self.x_clean, self.y\n",
    "\n",
    "        else:\n",
    "            return self.x_clean\n",
    "\n",
    "    def return_data(self):\n",
    "\n",
    "        return self.x_clean\n",
    "\n",
    "    def return_xy(self):\n",
    "\n",
    "        return self.x_clean, self.y_clean\n",
    "\n",
    "    def dumping_variable(self):\n",
    "\n",
    "        util.pickle_dump(self.imputer_num, config_data['imputer_num'])\n",
    "        util.pickle_dump(self.imputer_cat, config_data['imputer_cat'])\n",
    "        util.pickle_dump(self.encoder_ohe, config_data['ohe_path'])\n",
    "        util.pickle_dump(self.encoder_oe, config_data['le_path'])\n",
    "        util.pickle_dump(self.scaler, config_data['scaler_path'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try the function into train_set_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_train_ = preprocessing_data()\n",
    "\n",
    "x_train, y_train = preprocessing_train_.fit(train_set)\n",
    "\n",
    "preprocessing_train_.dumping_variable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc7_2_'></a>[Handling Non-Balancing Valid & Test set](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid, y_valid = preprocessing_train_.fit(\n",
    "                        valid_set,\n",
    "                        imputer_num = util.pickle_load(config_data[\"imputer_num\"]),\n",
    "                        imputer_cat = util.pickle_load(config_data[\"imputer_cat\"]),\n",
    "                        encoder_oe = util.pickle_load(config_data[\"le_path\"]),\n",
    "                        encoder_ohe = util.pickle_load(config_data[\"ohe_path\"]),\n",
    "                        scaler = util.pickle_load(config_data['scaler_path'])\n",
    ")\n",
    "\n",
    "x_test, y_test = preprocessing_train_.fit(\n",
    "                        test_set,\n",
    "                        imputer_num = util.pickle_load(config_data[\"imputer_num\"]),\n",
    "                        imputer_cat = util.pickle_load(config_data[\"imputer_cat\"]),\n",
    "                        encoder_oe = util.pickle_load(config_data[\"le_path\"]),\n",
    "                        encoder_ohe = util.pickle_load(config_data[\"ohe_path\"]),\n",
    "                        scaler = util.pickle_load(config_data['scaler_path'])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc7_3_'></a>[Handling Smote Data Set](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_smote_ = preprocessing_data()\n",
    "\n",
    "x_smote, y_smote = preprocessing_smote_.fit(train_set_smote)\n",
    "\n",
    "preprocessing_smote_.dumping_variable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid_smote, y_valid_smote = preprocessing_smote_.fit(\n",
    "                                valid_set_smote,\n",
    "                                imputer_num = util.pickle_load(config_data[\"imputer_num\"]),\n",
    "                                imputer_cat = util.pickle_load(config_data[\"imputer_cat\"]),\n",
    "                                encoder_oe = util.pickle_load(config_data[\"le_path\"]),\n",
    "                                encoder_ohe = util.pickle_load(config_data[\"ohe_path\"]),\n",
    "                                scaler = util.pickle_load(config_data['scaler_path'])\n",
    ")\n",
    "\n",
    "x_test_smote, y_test_smote = preprocessing_smote_.fit(\n",
    "                                test_set_smote,\n",
    "                                imputer_num = util.pickle_load(config_data[\"imputer_num\"]),\n",
    "                                imputer_cat = util.pickle_load(config_data[\"imputer_cat\"]),\n",
    "                                encoder_oe = util.pickle_load(config_data[\"le_path\"]),\n",
    "                                encoder_ohe = util.pickle_load(config_data[\"ohe_path\"]),\n",
    "                                scaler = util.pickle_load(config_data['scaler_path'])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc7_4_'></a>[Handling Over Data Set](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_over_ = preprocessing_data()\n",
    "\n",
    "x_over, y_over = preprocessing_over_.fit(train_set_over)\n",
    "\n",
    "preprocessing_over_.dumping_variable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid_over, y_valid_over = preprocessing_over_.fit(\n",
    "                                valid_set_over,\n",
    "                                imputer_num = util.pickle_load(config_data[\"imputer_num\"]),\n",
    "                                imputer_cat = util.pickle_load(config_data[\"imputer_cat\"]),\n",
    "                                encoder_oe = util.pickle_load(config_data[\"le_path\"]),\n",
    "                                encoder_ohe = util.pickle_load(config_data[\"ohe_path\"]),\n",
    "                                scaler = util.pickle_load(config_data['scaler_path'])\n",
    ")\n",
    "\n",
    "x_test_over, y_test_over = preprocessing_over_.fit(\n",
    "                                test_set_over,\n",
    "                                imputer_num = util.pickle_load(config_data[\"imputer_num\"]),\n",
    "                                imputer_cat = util.pickle_load(config_data[\"imputer_cat\"]),\n",
    "                                encoder_oe = util.pickle_load(config_data[\"le_path\"]),\n",
    "                                encoder_ohe = util.pickle_load(config_data[\"ohe_path\"]),\n",
    "                                scaler = util.pickle_load(config_data['scaler_path'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.5\n",
       "1    0.5\n",
       "Name: fraud_reported, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_over.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc8_'></a>[<b> Dump Train, Valid & Test Set </b>](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_final = {\n",
    "    \"nonbalance\" : x_train,\n",
    "    \"smote\" : x_smote,\n",
    "    \"oversampling\" : x_over\n",
    "}\n",
    "\n",
    "y_train_final = {\n",
    "    \"nonbalance\" : y_train,\n",
    "    \"smote\" : y_smote,\n",
    "    \"oversampling\" : y_over\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid_final = {\n",
    "    \"nonbalance\" : x_valid,\n",
    "    \"smote\" : x_valid_smote,\n",
    "    \"oversampling\" : x_valid_over\n",
    "}\n",
    "\n",
    "y_valid_final = {\n",
    "    \"nonbalance\" : y_valid,\n",
    "    \"smote\" : y_valid_smote,\n",
    "    \"oversampling\" : y_valid_over\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_final = {\n",
    "    \"nonbalance\" : x_test,\n",
    "    \"smote\" : x_test_smote,\n",
    "    \"oversampling\" : x_test_over\n",
    "}\n",
    "\n",
    "y_test_final = {\n",
    "    \"nonbalance\" : y_test,\n",
    "    \"smote\" : y_test_smote,\n",
    "    \"oversampling\" : y_test_over\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.pickle_dump(x_train_final, config_data['train_set_clean'][0])\n",
    "util.pickle_dump(y_train_final, config_data['train_set_clean'][1])\n",
    "\n",
    "util.pickle_dump(x_valid_final, config_data['valid_set_clean'][0])\n",
    "util.pickle_dump(y_valid_final, config_data['valid_set_clean'][1])\n",
    "\n",
    "util.pickle_dump(x_test_final, config_data['test_set_clean'][0])\n",
    "util.pickle_dump(y_test_final, config_data['test_set_clean'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "a90aeebcf29d64a654773811cc170cb25061cb2498f10ac689db374c7bf325de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
